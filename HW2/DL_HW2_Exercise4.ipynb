{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_HW2_Exercise4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGynqhoI0HZs"
      },
      "source": [
        "#Stu no: 99210259\n",
        "#stu name: Amir Pourmand"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uymp2t7Apac",
        "outputId": "d8cd29a4-3301-4036-d730-2da899465cbe"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri6LkA6AB6_N"
      },
      "source": [
        "cuda = torch.device('cuda')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsrU1VKY0QKH",
        "outputId": "a6ab933c-6b1b-4c8c-f879-f92a492321fb"
      },
      "source": [
        " !wget https://github.com/mralisoltani/CNN_Tumor/raw/main/Tumor.zip\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-04 19:48:40--  https://github.com/mralisoltani/CNN_Tumor/raw/main/Tumor.zip\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mralisoltani/CNN_Tumor/main/Tumor.zip [following]\n",
            "--2021-12-04 19:48:40--  https://raw.githubusercontent.com/mralisoltani/CNN_Tumor/main/Tumor.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14338568 (14M) [application/zip]\n",
            "Saving to: ‘Tumor.zip’\n",
            "\n",
            "Tumor.zip           100%[===================>]  13.67M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-12-04 19:48:42 (102 MB/s) - ‘Tumor.zip’ saved [14338568/14338568]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GeAI8cK0ZTh"
      },
      "source": [
        "!unzip /content/Tumor.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4w84NynAHH9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9QPnQZ_0Zv9"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "\n",
        "@author: Ali Soltani\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pds\n",
        "from torch.utils.data import DataLoader,TensorDataset,random_split\n",
        "\n",
        "############################################################## Loading Data\n",
        "n = 3762\n",
        "image=[]\n",
        "cw = os.getcwd().replace(os.sep, '/')\n",
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "for i in range(n):\n",
        "#    image.append(np.asarray(Image.open(cw + \"/Brain_Tumor/Image\" + str(i+1) + \".jpg\")))\n",
        "    image.append(np.array(Image.open(cw + \"/Brain_Tumor/Image\" + str(i+1) + \".jpg\").resize((48,48))))\n",
        "\n",
        "temp = pds.read_csv(cw + \"/Brain_Tumor.csv\",index_col=None, header=None).to_numpy()\n",
        "temp = temp[1:,1]\n",
        "targets = np.zeros((n,1),dtype=int)\n",
        "targets = []\n",
        "for i in range(n):\n",
        "    targets.append(int(temp[i]))\n",
        "\n",
        "data = np.array(image)\n",
        "data = data/255\n",
        "data = torch.from_numpy(data).permute((0,3,2,1))\n",
        "data = data.float().to(cuda)\n",
        "targets = torch.tensor(targets).to(cuda)\n",
        "dataset = TensorDataset(data,targets)\n",
        "batch_size = 4\n",
        "val_size = int(np.ceil(len(dataset)*0.2))\n",
        "train_size = len(dataset) - val_size \n",
        "\n",
        "train_data,test_data = random_split(dataset,[train_size,val_size])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data,batch_size = batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_data,batch_size = batch_size,shuffle=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWu_1de034Qq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vg4sLwgv0lR_",
        "outputId": "113838c7-4b27-4fb6-b3ac-41996e31cb1c"
      },
      "source": [
        "print(\"count of data:\", len(train_data))\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "for i in range(batch_size):\n",
        "    img = train_features[i].squeeze()\n",
        "    label = train_labels[i]\n",
        "    im = transforms.ToPILImage()(img).convert(\"RGB\")\n",
        "    plt.imshow(im)\n",
        "    plt.show()\n",
        "    print(f\"Label: {label}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count of data: 3009\n",
            "Feature batch shape: torch.Size([4, 3, 48, 48])\n",
            "Labels batch shape: torch.Size([4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCRXLlUO0nBN"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(3*48*48, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOXnJ0ju203e",
        "outputId": "543ea041-5aa6-4f7c-e48e-97c106fcd39d"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp5b27Bc_Xca",
        "outputId": "9acc2dcb-c1bb-4044-a8c1-e16a2d56a7a6"
      },
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=6912, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=24, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=24, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPd-IgTgAIIb"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sMcbd-3AIiF"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMMnQWavASxj",
        "outputId": "cb3157fe-9cce-4073-8c39-ef9315a38311"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    loss = test_loop(test_loader, model, loss_fn)\n",
        "    losses.append(loss)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.612874  [    0/ 3009]\n",
            "loss: 0.712673  [  400/ 3009]\n",
            "loss: 0.744615  [  800/ 3009]\n",
            "loss: 0.690195  [ 1200/ 3009]\n",
            "loss: 0.710857  [ 1600/ 3009]\n",
            "loss: 0.616541  [ 2000/ 3009]\n",
            "loss: 0.650407  [ 2400/ 3009]\n",
            "loss: 0.670259  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.8%, Avg loss: 0.609731 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.610377  [    0/ 3009]\n",
            "loss: 0.635636  [  400/ 3009]\n",
            "loss: 0.459467  [  800/ 3009]\n",
            "loss: 0.638018  [ 1200/ 3009]\n",
            "loss: 0.553621  [ 1600/ 3009]\n",
            "loss: 0.758643  [ 2000/ 3009]\n",
            "loss: 0.648250  [ 2400/ 3009]\n",
            "loss: 0.499889  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 79.0%, Avg loss: 0.501841 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.425109  [    0/ 3009]\n",
            "loss: 0.521330  [  400/ 3009]\n",
            "loss: 0.658485  [  800/ 3009]\n",
            "loss: 0.244719  [ 1200/ 3009]\n",
            "loss: 0.252357  [ 1600/ 3009]\n",
            "loss: 0.307023  [ 2000/ 3009]\n",
            "loss: 0.536315  [ 2400/ 3009]\n",
            "loss: 0.851961  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg loss: 0.463312 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.369217  [    0/ 3009]\n",
            "loss: 0.232987  [  400/ 3009]\n",
            "loss: 0.335672  [  800/ 3009]\n",
            "loss: 0.706650  [ 1200/ 3009]\n",
            "loss: 0.287788  [ 1600/ 3009]\n",
            "loss: 0.169689  [ 2000/ 3009]\n",
            "loss: 0.183748  [ 2400/ 3009]\n",
            "loss: 1.081773  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.5%, Avg loss: 0.449939 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.619481  [    0/ 3009]\n",
            "loss: 0.762072  [  400/ 3009]\n",
            "loss: 0.309186  [  800/ 3009]\n",
            "loss: 0.468054  [ 1200/ 3009]\n",
            "loss: 0.152687  [ 1600/ 3009]\n",
            "loss: 1.196430  [ 2000/ 3009]\n",
            "loss: 0.565655  [ 2400/ 3009]\n",
            "loss: 0.423156  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.440605 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.408311  [    0/ 3009]\n",
            "loss: 0.406658  [  400/ 3009]\n",
            "loss: 0.643183  [  800/ 3009]\n",
            "loss: 0.680348  [ 1200/ 3009]\n",
            "loss: 0.292098  [ 1600/ 3009]\n",
            "loss: 0.885864  [ 2000/ 3009]\n",
            "loss: 0.384026  [ 2400/ 3009]\n",
            "loss: 0.291240  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.429059 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.972317  [    0/ 3009]\n",
            "loss: 0.647492  [  400/ 3009]\n",
            "loss: 0.287916  [  800/ 3009]\n",
            "loss: 0.136399  [ 1200/ 3009]\n",
            "loss: 0.131110  [ 1600/ 3009]\n",
            "loss: 1.046456  [ 2000/ 3009]\n",
            "loss: 0.321376  [ 2400/ 3009]\n",
            "loss: 0.262513  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.428422 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.586174  [    0/ 3009]\n",
            "loss: 0.280675  [  400/ 3009]\n",
            "loss: 0.535293  [  800/ 3009]\n",
            "loss: 0.510741  [ 1200/ 3009]\n",
            "loss: 0.490539  [ 1600/ 3009]\n",
            "loss: 0.403635  [ 2000/ 3009]\n",
            "loss: 0.292357  [ 2400/ 3009]\n",
            "loss: 0.243813  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.425741 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.693683  [    0/ 3009]\n",
            "loss: 0.942616  [  400/ 3009]\n",
            "loss: 0.519126  [  800/ 3009]\n",
            "loss: 0.515375  [ 1200/ 3009]\n",
            "loss: 0.276121  [ 1600/ 3009]\n",
            "loss: 0.308702  [ 2000/ 3009]\n",
            "loss: 0.174399  [ 2400/ 3009]\n",
            "loss: 0.088865  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.404838 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.490923  [    0/ 3009]\n",
            "loss: 0.250209  [  400/ 3009]\n",
            "loss: 0.350554  [  800/ 3009]\n",
            "loss: 0.569447  [ 1200/ 3009]\n",
            "loss: 0.572317  [ 1600/ 3009]\n",
            "loss: 0.596234  [ 2000/ 3009]\n",
            "loss: 0.741490  [ 2400/ 3009]\n",
            "loss: 0.671194  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.393213 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.251380  [    0/ 3009]\n",
            "loss: 0.490289  [  400/ 3009]\n",
            "loss: 1.060655  [  800/ 3009]\n",
            "loss: 0.565315  [ 1200/ 3009]\n",
            "loss: 0.849334  [ 1600/ 3009]\n",
            "loss: 0.175850  [ 2000/ 3009]\n",
            "loss: 0.606803  [ 2400/ 3009]\n",
            "loss: 0.099015  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.387654 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.413961  [    0/ 3009]\n",
            "loss: 0.353818  [  400/ 3009]\n",
            "loss: 0.492692  [  800/ 3009]\n",
            "loss: 0.261699  [ 1200/ 3009]\n",
            "loss: 0.435635  [ 1600/ 3009]\n",
            "loss: 0.699563  [ 2000/ 3009]\n",
            "loss: 0.286699  [ 2400/ 3009]\n",
            "loss: 0.353499  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.394087 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.739688  [    0/ 3009]\n",
            "loss: 0.808778  [  400/ 3009]\n",
            "loss: 0.371513  [  800/ 3009]\n",
            "loss: 0.347069  [ 1200/ 3009]\n",
            "loss: 0.914741  [ 1600/ 3009]\n",
            "loss: 0.343169  [ 2000/ 3009]\n",
            "loss: 0.199363  [ 2400/ 3009]\n",
            "loss: 0.571568  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.373210 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.242214  [    0/ 3009]\n",
            "loss: 0.529473  [  400/ 3009]\n",
            "loss: 0.110571  [  800/ 3009]\n",
            "loss: 0.219881  [ 1200/ 3009]\n",
            "loss: 0.605801  [ 1600/ 3009]\n",
            "loss: 0.729178  [ 2000/ 3009]\n",
            "loss: 0.451821  [ 2400/ 3009]\n",
            "loss: 0.042259  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.387483 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.652645  [    0/ 3009]\n",
            "loss: 0.660620  [  400/ 3009]\n",
            "loss: 0.151364  [  800/ 3009]\n",
            "loss: 0.585606  [ 1200/ 3009]\n",
            "loss: 0.187032  [ 1600/ 3009]\n",
            "loss: 0.118159  [ 2000/ 3009]\n",
            "loss: 0.308171  [ 2400/ 3009]\n",
            "loss: 0.441323  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.356562 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.414405  [    0/ 3009]\n",
            "loss: 0.385131  [  400/ 3009]\n",
            "loss: 0.459647  [  800/ 3009]\n",
            "loss: 0.491250  [ 1200/ 3009]\n",
            "loss: 0.252520  [ 1600/ 3009]\n",
            "loss: 0.558517  [ 2000/ 3009]\n",
            "loss: 0.276253  [ 2400/ 3009]\n",
            "loss: 0.214704  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.347331 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.311998  [    0/ 3009]\n",
            "loss: 0.367243  [  400/ 3009]\n",
            "loss: 0.238140  [  800/ 3009]\n",
            "loss: 0.252870  [ 1200/ 3009]\n",
            "loss: 0.517217  [ 1600/ 3009]\n",
            "loss: 0.154063  [ 2000/ 3009]\n",
            "loss: 0.574752  [ 2400/ 3009]\n",
            "loss: 0.205588  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.359407 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.200745  [    0/ 3009]\n",
            "loss: 0.193018  [  400/ 3009]\n",
            "loss: 0.436503  [  800/ 3009]\n",
            "loss: 0.351975  [ 1200/ 3009]\n",
            "loss: 0.262803  [ 1600/ 3009]\n",
            "loss: 0.339808  [ 2000/ 3009]\n",
            "loss: 0.155746  [ 2400/ 3009]\n",
            "loss: 0.349147  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.338214 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.874758  [    0/ 3009]\n",
            "loss: 0.187211  [  400/ 3009]\n",
            "loss: 0.266102  [  800/ 3009]\n",
            "loss: 0.684857  [ 1200/ 3009]\n",
            "loss: 0.126850  [ 1600/ 3009]\n",
            "loss: 0.405240  [ 2000/ 3009]\n",
            "loss: 0.468569  [ 2400/ 3009]\n",
            "loss: 0.170313  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 0.438182 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.288537  [    0/ 3009]\n",
            "loss: 0.459627  [  400/ 3009]\n",
            "loss: 0.376274  [  800/ 3009]\n",
            "loss: 0.371028  [ 1200/ 3009]\n",
            "loss: 0.326232  [ 1600/ 3009]\n",
            "loss: 0.406395  [ 2000/ 3009]\n",
            "loss: 0.324307  [ 2400/ 3009]\n",
            "loss: 0.169120  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.333102 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.579771  [    0/ 3009]\n",
            "loss: 0.043862  [  400/ 3009]\n",
            "loss: 0.373217  [  800/ 3009]\n",
            "loss: 0.137673  [ 1200/ 3009]\n",
            "loss: 0.431986  [ 1600/ 3009]\n",
            "loss: 0.180526  [ 2000/ 3009]\n",
            "loss: 0.343980  [ 2400/ 3009]\n",
            "loss: 0.182292  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.304675 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.243134  [    0/ 3009]\n",
            "loss: 0.519196  [  400/ 3009]\n",
            "loss: 0.151192  [  800/ 3009]\n",
            "loss: 0.814512  [ 1200/ 3009]\n",
            "loss: 0.336175  [ 1600/ 3009]\n",
            "loss: 0.184668  [ 2000/ 3009]\n",
            "loss: 0.442557  [ 2400/ 3009]\n",
            "loss: 0.559415  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.315558 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.241646  [    0/ 3009]\n",
            "loss: 0.121983  [  400/ 3009]\n",
            "loss: 0.166792  [  800/ 3009]\n",
            "loss: 0.728975  [ 1200/ 3009]\n",
            "loss: 0.853758  [ 1600/ 3009]\n",
            "loss: 0.247208  [ 2000/ 3009]\n",
            "loss: 0.210000  [ 2400/ 3009]\n",
            "loss: 0.575594  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.287921 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.204562  [    0/ 3009]\n",
            "loss: 0.636178  [  400/ 3009]\n",
            "loss: 0.353221  [  800/ 3009]\n",
            "loss: 0.145395  [ 1200/ 3009]\n",
            "loss: 0.019980  [ 1600/ 3009]\n",
            "loss: 0.133911  [ 2000/ 3009]\n",
            "loss: 0.529071  [ 2400/ 3009]\n",
            "loss: 0.679501  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.283882 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.368221  [    0/ 3009]\n",
            "loss: 0.365529  [  400/ 3009]\n",
            "loss: 0.126380  [  800/ 3009]\n",
            "loss: 0.257044  [ 1200/ 3009]\n",
            "loss: 0.531492  [ 1600/ 3009]\n",
            "loss: 0.546171  [ 2000/ 3009]\n",
            "loss: 0.077782  [ 2400/ 3009]\n",
            "loss: 0.156337  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.291231 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.077332  [    0/ 3009]\n",
            "loss: 0.442437  [  400/ 3009]\n",
            "loss: 0.173262  [  800/ 3009]\n",
            "loss: 0.342794  [ 1200/ 3009]\n",
            "loss: 0.190451  [ 1600/ 3009]\n",
            "loss: 0.252560  [ 2000/ 3009]\n",
            "loss: 0.106319  [ 2400/ 3009]\n",
            "loss: 0.384746  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.379764 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.043573  [    0/ 3009]\n",
            "loss: 0.257958  [  400/ 3009]\n",
            "loss: 0.113562  [  800/ 3009]\n",
            "loss: 0.116501  [ 1200/ 3009]\n",
            "loss: 0.608645  [ 1600/ 3009]\n",
            "loss: 0.293663  [ 2000/ 3009]\n",
            "loss: 0.869821  [ 2400/ 3009]\n",
            "loss: 0.050862  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.263382 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.451397  [    0/ 3009]\n",
            "loss: 0.140293  [  400/ 3009]\n",
            "loss: 0.103293  [  800/ 3009]\n",
            "loss: 0.364420  [ 1200/ 3009]\n",
            "loss: 0.919895  [ 1600/ 3009]\n",
            "loss: 0.387272  [ 2000/ 3009]\n",
            "loss: 0.113433  [ 2400/ 3009]\n",
            "loss: 0.396482  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.287503 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.240750  [    0/ 3009]\n",
            "loss: 0.135038  [  400/ 3009]\n",
            "loss: 0.136483  [  800/ 3009]\n",
            "loss: 0.211313  [ 1200/ 3009]\n",
            "loss: 0.404109  [ 1600/ 3009]\n",
            "loss: 0.102361  [ 2000/ 3009]\n",
            "loss: 0.626404  [ 2400/ 3009]\n",
            "loss: 0.308952  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.303608 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.325404  [    0/ 3009]\n",
            "loss: 0.717290  [  400/ 3009]\n",
            "loss: 0.066294  [  800/ 3009]\n",
            "loss: 0.311741  [ 1200/ 3009]\n",
            "loss: 0.263317  [ 1600/ 3009]\n",
            "loss: 0.092243  [ 2000/ 3009]\n",
            "loss: 0.045577  [ 2400/ 3009]\n",
            "loss: 0.319441  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.320189 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.534368  [    0/ 3009]\n",
            "loss: 0.183639  [  400/ 3009]\n",
            "loss: 0.370600  [  800/ 3009]\n",
            "loss: 0.068155  [ 1200/ 3009]\n",
            "loss: 0.654767  [ 1600/ 3009]\n",
            "loss: 0.113649  [ 2000/ 3009]\n",
            "loss: 0.090134  [ 2400/ 3009]\n",
            "loss: 0.344198  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.242058 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.574545  [    0/ 3009]\n",
            "loss: 0.063914  [  400/ 3009]\n",
            "loss: 0.198321  [  800/ 3009]\n",
            "loss: 0.197522  [ 1200/ 3009]\n",
            "loss: 0.062481  [ 1600/ 3009]\n",
            "loss: 0.398479  [ 2000/ 3009]\n",
            "loss: 0.067294  [ 2400/ 3009]\n",
            "loss: 0.121848  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.229504 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.155469  [    0/ 3009]\n",
            "loss: 0.525266  [  400/ 3009]\n",
            "loss: 0.061572  [  800/ 3009]\n",
            "loss: 0.099578  [ 1200/ 3009]\n",
            "loss: 0.167400  [ 1600/ 3009]\n",
            "loss: 0.133902  [ 2000/ 3009]\n",
            "loss: 0.022538  [ 2400/ 3009]\n",
            "loss: 0.120725  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.273928 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.380336  [    0/ 3009]\n",
            "loss: 0.092845  [  400/ 3009]\n",
            "loss: 0.227845  [  800/ 3009]\n",
            "loss: 0.403331  [ 1200/ 3009]\n",
            "loss: 0.419965  [ 1600/ 3009]\n",
            "loss: 0.309798  [ 2000/ 3009]\n",
            "loss: 0.153747  [ 2400/ 3009]\n",
            "loss: 0.248192  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.424367 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.019522  [    0/ 3009]\n",
            "loss: 0.033974  [  400/ 3009]\n",
            "loss: 0.030182  [  800/ 3009]\n",
            "loss: 0.490474  [ 1200/ 3009]\n",
            "loss: 0.404290  [ 1600/ 3009]\n",
            "loss: 0.031227  [ 2000/ 3009]\n",
            "loss: 0.060337  [ 2400/ 3009]\n",
            "loss: 0.035989  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.247775 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.136393  [    0/ 3009]\n",
            "loss: 0.434957  [  400/ 3009]\n",
            "loss: 0.068037  [  800/ 3009]\n",
            "loss: 0.250394  [ 1200/ 3009]\n",
            "loss: 0.379639  [ 1600/ 3009]\n",
            "loss: 0.154445  [ 2000/ 3009]\n",
            "loss: 0.421805  [ 2400/ 3009]\n",
            "loss: 0.107628  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.232820 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.214086  [    0/ 3009]\n",
            "loss: 0.256247  [  400/ 3009]\n",
            "loss: 0.495287  [  800/ 3009]\n",
            "loss: 0.031020  [ 1200/ 3009]\n",
            "loss: 0.155265  [ 1600/ 3009]\n",
            "loss: 0.371716  [ 2000/ 3009]\n",
            "loss: 0.227169  [ 2400/ 3009]\n",
            "loss: 0.337771  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.216823 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.096700  [    0/ 3009]\n",
            "loss: 0.144805  [  400/ 3009]\n",
            "loss: 0.208566  [  800/ 3009]\n",
            "loss: 0.069215  [ 1200/ 3009]\n",
            "loss: 0.052309  [ 1600/ 3009]\n",
            "loss: 0.520875  [ 2000/ 3009]\n",
            "loss: 0.346237  [ 2400/ 3009]\n",
            "loss: 0.175983  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.218782 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.305555  [    0/ 3009]\n",
            "loss: 0.150947  [  400/ 3009]\n",
            "loss: 0.500910  [  800/ 3009]\n",
            "loss: 0.219239  [ 1200/ 3009]\n",
            "loss: 0.102949  [ 1600/ 3009]\n",
            "loss: 0.114788  [ 2000/ 3009]\n",
            "loss: 0.164632  [ 2400/ 3009]\n",
            "loss: 0.062595  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.226254 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.006157  [    0/ 3009]\n",
            "loss: 0.191176  [  400/ 3009]\n",
            "loss: 0.359908  [  800/ 3009]\n",
            "loss: 0.117878  [ 1200/ 3009]\n",
            "loss: 0.083638  [ 1600/ 3009]\n",
            "loss: 0.127077  [ 2000/ 3009]\n",
            "loss: 0.101555  [ 2400/ 3009]\n",
            "loss: 0.026675  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.209517 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.461294  [    0/ 3009]\n",
            "loss: 0.113928  [  400/ 3009]\n",
            "loss: 0.074724  [  800/ 3009]\n",
            "loss: 0.534803  [ 1200/ 3009]\n",
            "loss: 0.017591  [ 1600/ 3009]\n",
            "loss: 0.078571  [ 2000/ 3009]\n",
            "loss: 0.137161  [ 2400/ 3009]\n",
            "loss: 0.194793  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.204340 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.009259  [    0/ 3009]\n",
            "loss: 0.102977  [  400/ 3009]\n",
            "loss: 0.011841  [  800/ 3009]\n",
            "loss: 0.122268  [ 1200/ 3009]\n",
            "loss: 0.522349  [ 1600/ 3009]\n",
            "loss: 0.016986  [ 2000/ 3009]\n",
            "loss: 0.127133  [ 2400/ 3009]\n",
            "loss: 0.621686  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.214583 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.019270  [    0/ 3009]\n",
            "loss: 0.194109  [  400/ 3009]\n",
            "loss: 0.098511  [  800/ 3009]\n",
            "loss: 0.510885  [ 1200/ 3009]\n",
            "loss: 0.074684  [ 1600/ 3009]\n",
            "loss: 0.028622  [ 2000/ 3009]\n",
            "loss: 0.003813  [ 2400/ 3009]\n",
            "loss: 0.217556  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.213688 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.249906  [    0/ 3009]\n",
            "loss: 0.036435  [  400/ 3009]\n",
            "loss: 0.382848  [  800/ 3009]\n",
            "loss: 0.138155  [ 1200/ 3009]\n",
            "loss: 0.015072  [ 1600/ 3009]\n",
            "loss: 0.183296  [ 2000/ 3009]\n",
            "loss: 0.765493  [ 2400/ 3009]\n",
            "loss: 0.002745  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.192210 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.048382  [    0/ 3009]\n",
            "loss: 0.007643  [  400/ 3009]\n",
            "loss: 0.002455  [  800/ 3009]\n",
            "loss: 0.314233  [ 1200/ 3009]\n",
            "loss: 0.250882  [ 1600/ 3009]\n",
            "loss: 0.187964  [ 2000/ 3009]\n",
            "loss: 0.310398  [ 2400/ 3009]\n",
            "loss: 0.292651  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.181595 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.526552  [    0/ 3009]\n",
            "loss: 0.350501  [  400/ 3009]\n",
            "loss: 0.018045  [  800/ 3009]\n",
            "loss: 0.241172  [ 1200/ 3009]\n",
            "loss: 0.024312  [ 1600/ 3009]\n",
            "loss: 0.064598  [ 2000/ 3009]\n",
            "loss: 0.066437  [ 2400/ 3009]\n",
            "loss: 0.121476  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.192466 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.237301  [    0/ 3009]\n",
            "loss: 0.018461  [  400/ 3009]\n",
            "loss: 0.023916  [  800/ 3009]\n",
            "loss: 0.106190  [ 1200/ 3009]\n",
            "loss: 0.033839  [ 1600/ 3009]\n",
            "loss: 0.025127  [ 2000/ 3009]\n",
            "loss: 0.095227  [ 2400/ 3009]\n",
            "loss: 0.449622  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.198553 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.004209  [    0/ 3009]\n",
            "loss: 0.232386  [  400/ 3009]\n",
            "loss: 0.401816  [  800/ 3009]\n",
            "loss: 0.320880  [ 1200/ 3009]\n",
            "loss: 0.032645  [ 1600/ 3009]\n",
            "loss: 0.070538  [ 2000/ 3009]\n",
            "loss: 0.078433  [ 2400/ 3009]\n",
            "loss: 0.031259  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.176062 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.280083  [    0/ 3009]\n",
            "loss: 0.034082  [  400/ 3009]\n",
            "loss: 0.059922  [  800/ 3009]\n",
            "loss: 0.024797  [ 1200/ 3009]\n",
            "loss: 0.078281  [ 1600/ 3009]\n",
            "loss: 0.443106  [ 2000/ 3009]\n",
            "loss: 0.164287  [ 2400/ 3009]\n",
            "loss: 0.131497  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.238801 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.008298  [    0/ 3009]\n",
            "loss: 0.043125  [  400/ 3009]\n",
            "loss: 0.075283  [  800/ 3009]\n",
            "loss: 0.077505  [ 1200/ 3009]\n",
            "loss: 0.283944  [ 1600/ 3009]\n",
            "loss: 0.121972  [ 2000/ 3009]\n",
            "loss: 0.008125  [ 2400/ 3009]\n",
            "loss: 0.080740  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.191261 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.044427  [    0/ 3009]\n",
            "loss: 0.186360  [  400/ 3009]\n",
            "loss: 0.002991  [  800/ 3009]\n",
            "loss: 0.129555  [ 1200/ 3009]\n",
            "loss: 0.063185  [ 1600/ 3009]\n",
            "loss: 0.137349  [ 2000/ 3009]\n",
            "loss: 0.455101  [ 2400/ 3009]\n",
            "loss: 0.053374  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.172863 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.143869  [    0/ 3009]\n",
            "loss: 0.026640  [  400/ 3009]\n",
            "loss: 0.060242  [  800/ 3009]\n",
            "loss: 0.087954  [ 1200/ 3009]\n",
            "loss: 0.110793  [ 1600/ 3009]\n",
            "loss: 0.133597  [ 2000/ 3009]\n",
            "loss: 0.013762  [ 2400/ 3009]\n",
            "loss: 0.129186  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.195690 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.627114  [    0/ 3009]\n",
            "loss: 0.474869  [  400/ 3009]\n",
            "loss: 0.213273  [  800/ 3009]\n",
            "loss: 0.040031  [ 1200/ 3009]\n",
            "loss: 0.007852  [ 1600/ 3009]\n",
            "loss: 0.031571  [ 2000/ 3009]\n",
            "loss: 0.001123  [ 2400/ 3009]\n",
            "loss: 0.028975  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.170234 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.074014  [    0/ 3009]\n",
            "loss: 0.036522  [  400/ 3009]\n",
            "loss: 0.025333  [  800/ 3009]\n",
            "loss: 0.024615  [ 1200/ 3009]\n",
            "loss: 0.063585  [ 1600/ 3009]\n",
            "loss: 0.166636  [ 2000/ 3009]\n",
            "loss: 0.134701  [ 2400/ 3009]\n",
            "loss: 0.147738  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.177144 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.035748  [    0/ 3009]\n",
            "loss: 0.011622  [  400/ 3009]\n",
            "loss: 0.015642  [  800/ 3009]\n",
            "loss: 0.351276  [ 1200/ 3009]\n",
            "loss: 0.360488  [ 1600/ 3009]\n",
            "loss: 0.028831  [ 2000/ 3009]\n",
            "loss: 0.750125  [ 2400/ 3009]\n",
            "loss: 0.006516  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.195945 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.032789  [    0/ 3009]\n",
            "loss: 0.077465  [  400/ 3009]\n",
            "loss: 0.373449  [  800/ 3009]\n",
            "loss: 0.178403  [ 1200/ 3009]\n",
            "loss: 0.041034  [ 1600/ 3009]\n",
            "loss: 0.272264  [ 2000/ 3009]\n",
            "loss: 0.090671  [ 2400/ 3009]\n",
            "loss: 0.478518  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.166679 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.374019  [    0/ 3009]\n",
            "loss: 0.063673  [  400/ 3009]\n",
            "loss: 0.116436  [  800/ 3009]\n",
            "loss: 0.044060  [ 1200/ 3009]\n",
            "loss: 0.020648  [ 1600/ 3009]\n",
            "loss: 0.317455  [ 2000/ 3009]\n",
            "loss: 0.016334  [ 2400/ 3009]\n",
            "loss: 0.136470  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.173969 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.101519  [    0/ 3009]\n",
            "loss: 0.071241  [  400/ 3009]\n",
            "loss: 0.150820  [  800/ 3009]\n",
            "loss: 0.042686  [ 1200/ 3009]\n",
            "loss: 0.021328  [ 1600/ 3009]\n",
            "loss: 0.080425  [ 2000/ 3009]\n",
            "loss: 0.288905  [ 2400/ 3009]\n",
            "loss: 0.006239  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.177651 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.037491  [    0/ 3009]\n",
            "loss: 0.003153  [  400/ 3009]\n",
            "loss: 0.253904  [  800/ 3009]\n",
            "loss: 0.137205  [ 1200/ 3009]\n",
            "loss: 0.329658  [ 1600/ 3009]\n",
            "loss: 0.357776  [ 2000/ 3009]\n",
            "loss: 0.881824  [ 2400/ 3009]\n",
            "loss: 0.095342  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.169382 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.645445  [    0/ 3009]\n",
            "loss: 0.011491  [  400/ 3009]\n",
            "loss: 0.107692  [  800/ 3009]\n",
            "loss: 0.069701  [ 1200/ 3009]\n",
            "loss: 0.037588  [ 1600/ 3009]\n",
            "loss: 0.721339  [ 2000/ 3009]\n",
            "loss: 0.373313  [ 2400/ 3009]\n",
            "loss: 0.023436  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.243987 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.006850  [    0/ 3009]\n",
            "loss: 0.004590  [  400/ 3009]\n",
            "loss: 0.099188  [  800/ 3009]\n",
            "loss: 0.014713  [ 1200/ 3009]\n",
            "loss: 0.049664  [ 1600/ 3009]\n",
            "loss: 0.039915  [ 2000/ 3009]\n",
            "loss: 0.083186  [ 2400/ 3009]\n",
            "loss: 0.061643  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.219652 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.143806  [    0/ 3009]\n",
            "loss: 0.165197  [  400/ 3009]\n",
            "loss: 0.039134  [  800/ 3009]\n",
            "loss: 0.225474  [ 1200/ 3009]\n",
            "loss: 0.257318  [ 1600/ 3009]\n",
            "loss: 0.216942  [ 2000/ 3009]\n",
            "loss: 0.169730  [ 2400/ 3009]\n",
            "loss: 0.000418  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.371053 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.513983  [    0/ 3009]\n",
            "loss: 0.528835  [  400/ 3009]\n",
            "loss: 0.008454  [  800/ 3009]\n",
            "loss: 0.156376  [ 1200/ 3009]\n",
            "loss: 0.099866  [ 1600/ 3009]\n",
            "loss: 0.076091  [ 2000/ 3009]\n",
            "loss: 0.034282  [ 2400/ 3009]\n",
            "loss: 0.004475  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.168315 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.254291  [    0/ 3009]\n",
            "loss: 0.268837  [  400/ 3009]\n",
            "loss: 0.113617  [  800/ 3009]\n",
            "loss: 0.462906  [ 1200/ 3009]\n",
            "loss: 0.035124  [ 1600/ 3009]\n",
            "loss: 0.201200  [ 2000/ 3009]\n",
            "loss: 0.038360  [ 2400/ 3009]\n",
            "loss: 0.038572  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.182171 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.022693  [    0/ 3009]\n",
            "loss: 0.052663  [  400/ 3009]\n",
            "loss: 0.102111  [  800/ 3009]\n",
            "loss: 0.020169  [ 1200/ 3009]\n",
            "loss: 0.640791  [ 1600/ 3009]\n",
            "loss: 0.272567  [ 2000/ 3009]\n",
            "loss: 0.009876  [ 2400/ 3009]\n",
            "loss: 0.074759  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.203175 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.037524  [    0/ 3009]\n",
            "loss: 0.140557  [  400/ 3009]\n",
            "loss: 0.022173  [  800/ 3009]\n",
            "loss: 0.160867  [ 1200/ 3009]\n",
            "loss: 0.146776  [ 1600/ 3009]\n",
            "loss: 0.038691  [ 2000/ 3009]\n",
            "loss: 0.096679  [ 2400/ 3009]\n",
            "loss: 1.046202  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.157990 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.000903  [    0/ 3009]\n",
            "loss: 0.461546  [  400/ 3009]\n",
            "loss: 0.373352  [  800/ 3009]\n",
            "loss: 0.004955  [ 1200/ 3009]\n",
            "loss: 0.205911  [ 1600/ 3009]\n",
            "loss: 0.028938  [ 2000/ 3009]\n",
            "loss: 0.041878  [ 2400/ 3009]\n",
            "loss: 0.018624  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.167001 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.115579  [    0/ 3009]\n",
            "loss: 0.213361  [  400/ 3009]\n",
            "loss: 0.009721  [  800/ 3009]\n",
            "loss: 0.092563  [ 1200/ 3009]\n",
            "loss: 0.050504  [ 1600/ 3009]\n",
            "loss: 0.002960  [ 2000/ 3009]\n",
            "loss: 0.270609  [ 2400/ 3009]\n",
            "loss: 0.013008  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 2.038542 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 1.104445  [    0/ 3009]\n",
            "loss: 0.010758  [  400/ 3009]\n",
            "loss: 0.207830  [  800/ 3009]\n",
            "loss: 0.376282  [ 1200/ 3009]\n",
            "loss: 0.010249  [ 1600/ 3009]\n",
            "loss: 0.011536  [ 2000/ 3009]\n",
            "loss: 0.025457  [ 2400/ 3009]\n",
            "loss: 0.000742  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.157803 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.004517  [    0/ 3009]\n",
            "loss: 0.021887  [  400/ 3009]\n",
            "loss: 0.392092  [  800/ 3009]\n",
            "loss: 0.021333  [ 1200/ 3009]\n",
            "loss: 0.029881  [ 1600/ 3009]\n",
            "loss: 0.014090  [ 2000/ 3009]\n",
            "loss: 0.576094  [ 2400/ 3009]\n",
            "loss: 0.016256  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.196472 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.015786  [    0/ 3009]\n",
            "loss: 0.024099  [  400/ 3009]\n",
            "loss: 0.010376  [  800/ 3009]\n",
            "loss: 0.270794  [ 1200/ 3009]\n",
            "loss: 0.006614  [ 1600/ 3009]\n",
            "loss: 0.075882  [ 2000/ 3009]\n",
            "loss: 0.201820  [ 2400/ 3009]\n",
            "loss: 0.106887  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.179289 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.066107  [    0/ 3009]\n",
            "loss: 0.044215  [  400/ 3009]\n",
            "loss: 0.039005  [  800/ 3009]\n",
            "loss: 0.040244  [ 1200/ 3009]\n",
            "loss: 0.112673  [ 1600/ 3009]\n",
            "loss: 0.066581  [ 2000/ 3009]\n",
            "loss: 0.014780  [ 2400/ 3009]\n",
            "loss: 0.001996  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.156728 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.054308  [    0/ 3009]\n",
            "loss: 0.135788  [  400/ 3009]\n",
            "loss: 0.488879  [  800/ 3009]\n",
            "loss: 0.058845  [ 1200/ 3009]\n",
            "loss: 0.001655  [ 1600/ 3009]\n",
            "loss: 0.170348  [ 2000/ 3009]\n",
            "loss: 0.597990  [ 2400/ 3009]\n",
            "loss: 0.012858  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.167063 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.006741  [    0/ 3009]\n",
            "loss: 0.009878  [  400/ 3009]\n",
            "loss: 0.023172  [  800/ 3009]\n",
            "loss: 0.049223  [ 1200/ 3009]\n",
            "loss: 0.035407  [ 1600/ 3009]\n",
            "loss: 0.281755  [ 2000/ 3009]\n",
            "loss: 0.039603  [ 2400/ 3009]\n",
            "loss: 0.014024  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.173177 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.069044  [    0/ 3009]\n",
            "loss: 0.013170  [  400/ 3009]\n",
            "loss: 0.075636  [  800/ 3009]\n",
            "loss: 0.023451  [ 1200/ 3009]\n",
            "loss: 0.006656  [ 1600/ 3009]\n",
            "loss: 0.006781  [ 2000/ 3009]\n",
            "loss: 0.040001  [ 2400/ 3009]\n",
            "loss: 0.026015  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.154842 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.129830  [    0/ 3009]\n",
            "loss: 0.040514  [  400/ 3009]\n",
            "loss: 0.097983  [  800/ 3009]\n",
            "loss: 0.010570  [ 1200/ 3009]\n",
            "loss: 0.363309  [ 1600/ 3009]\n",
            "loss: 0.000646  [ 2000/ 3009]\n",
            "loss: 1.124698  [ 2400/ 3009]\n",
            "loss: 0.000920  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.158166 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.048524  [    0/ 3009]\n",
            "loss: 0.013145  [  400/ 3009]\n",
            "loss: 0.020278  [  800/ 3009]\n",
            "loss: 0.033555  [ 1200/ 3009]\n",
            "loss: 0.019650  [ 1600/ 3009]\n",
            "loss: 0.019511  [ 2000/ 3009]\n",
            "loss: 0.086447  [ 2400/ 3009]\n",
            "loss: 0.087477  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.156554 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.033737  [    0/ 3009]\n",
            "loss: 0.000792  [  400/ 3009]\n",
            "loss: 0.252864  [  800/ 3009]\n",
            "loss: 0.099363  [ 1200/ 3009]\n",
            "loss: 0.077244  [ 1600/ 3009]\n",
            "loss: 0.008394  [ 2000/ 3009]\n",
            "loss: 0.384961  [ 2400/ 3009]\n",
            "loss: 0.036216  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.159181 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.000724  [    0/ 3009]\n",
            "loss: 0.014339  [  400/ 3009]\n",
            "loss: 0.066182  [  800/ 3009]\n",
            "loss: 0.110747  [ 1200/ 3009]\n",
            "loss: 0.059909  [ 1600/ 3009]\n",
            "loss: 0.487052  [ 2000/ 3009]\n",
            "loss: 0.352145  [ 2400/ 3009]\n",
            "loss: 0.001679  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.245481 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.031259  [    0/ 3009]\n",
            "loss: 0.092865  [  400/ 3009]\n",
            "loss: 0.002832  [  800/ 3009]\n",
            "loss: 0.165064  [ 1200/ 3009]\n",
            "loss: 0.002293  [ 1600/ 3009]\n",
            "loss: 0.059774  [ 2000/ 3009]\n",
            "loss: 0.000781  [ 2400/ 3009]\n",
            "loss: 0.154801  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.159270 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.024156  [    0/ 3009]\n",
            "loss: 0.031090  [  400/ 3009]\n",
            "loss: 0.006847  [  800/ 3009]\n",
            "loss: 0.030935  [ 1200/ 3009]\n",
            "loss: 0.217824  [ 1600/ 3009]\n",
            "loss: 0.020595  [ 2000/ 3009]\n",
            "loss: 0.025340  [ 2400/ 3009]\n",
            "loss: 0.311222  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.171679 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.001649  [    0/ 3009]\n",
            "loss: 0.043509  [  400/ 3009]\n",
            "loss: 0.570816  [  800/ 3009]\n",
            "loss: 0.002152  [ 1200/ 3009]\n",
            "loss: 0.066446  [ 1600/ 3009]\n",
            "loss: 0.005270  [ 2000/ 3009]\n",
            "loss: 0.026196  [ 2400/ 3009]\n",
            "loss: 0.007359  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.202278 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.000882  [    0/ 3009]\n",
            "loss: 0.051283  [  400/ 3009]\n",
            "loss: 0.266509  [  800/ 3009]\n",
            "loss: 0.018254  [ 1200/ 3009]\n",
            "loss: 0.101562  [ 1600/ 3009]\n",
            "loss: 0.041997  [ 2000/ 3009]\n",
            "loss: 0.023880  [ 2400/ 3009]\n",
            "loss: 0.227639  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.183190 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.007798  [    0/ 3009]\n",
            "loss: 0.000857  [  400/ 3009]\n",
            "loss: 0.034641  [  800/ 3009]\n",
            "loss: 0.003413  [ 1200/ 3009]\n",
            "loss: 0.009463  [ 1600/ 3009]\n",
            "loss: 0.047884  [ 2000/ 3009]\n",
            "loss: 0.091985  [ 2400/ 3009]\n",
            "loss: 0.044464  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.163869 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.020284  [    0/ 3009]\n",
            "loss: 0.063107  [  400/ 3009]\n",
            "loss: 0.000190  [  800/ 3009]\n",
            "loss: 0.005738  [ 1200/ 3009]\n",
            "loss: 0.080214  [ 1600/ 3009]\n",
            "loss: 0.008644  [ 2000/ 3009]\n",
            "loss: 0.005532  [ 2400/ 3009]\n",
            "loss: 0.018630  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.159843 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.002318  [    0/ 3009]\n",
            "loss: 0.005261  [  400/ 3009]\n",
            "loss: 0.208498  [  800/ 3009]\n",
            "loss: 0.096166  [ 1200/ 3009]\n",
            "loss: 0.006423  [ 1600/ 3009]\n",
            "loss: 0.373555  [ 2000/ 3009]\n",
            "loss: 0.020800  [ 2400/ 3009]\n",
            "loss: 0.013847  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.195176 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.001203  [    0/ 3009]\n",
            "loss: 0.047656  [  400/ 3009]\n",
            "loss: 0.175541  [  800/ 3009]\n",
            "loss: 0.023774  [ 1200/ 3009]\n",
            "loss: 0.679213  [ 1600/ 3009]\n",
            "loss: 0.689421  [ 2000/ 3009]\n",
            "loss: 0.056002  [ 2400/ 3009]\n",
            "loss: 0.019270  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.153779 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.011208  [    0/ 3009]\n",
            "loss: 0.009703  [  400/ 3009]\n",
            "loss: 0.010386  [  800/ 3009]\n",
            "loss: 0.022391  [ 1200/ 3009]\n",
            "loss: 0.008434  [ 1600/ 3009]\n",
            "loss: 0.191793  [ 2000/ 3009]\n",
            "loss: 0.623906  [ 2400/ 3009]\n",
            "loss: 0.013278  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.150847 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.018373  [    0/ 3009]\n",
            "loss: 0.054582  [  400/ 3009]\n",
            "loss: 0.005354  [  800/ 3009]\n",
            "loss: 0.232555  [ 1200/ 3009]\n",
            "loss: 0.071037  [ 1600/ 3009]\n",
            "loss: 0.011367  [ 2000/ 3009]\n",
            "loss: 0.036455  [ 2400/ 3009]\n",
            "loss: 0.044183  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.156266 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.004823  [    0/ 3009]\n",
            "loss: 0.083422  [  400/ 3009]\n",
            "loss: 0.423318  [  800/ 3009]\n",
            "loss: 0.013316  [ 1200/ 3009]\n",
            "loss: 0.132344  [ 1600/ 3009]\n",
            "loss: 0.111381  [ 2000/ 3009]\n",
            "loss: 0.000617  [ 2400/ 3009]\n",
            "loss: 0.016089  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.173889 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.005728  [    0/ 3009]\n",
            "loss: 0.266697  [  400/ 3009]\n",
            "loss: 0.001900  [  800/ 3009]\n",
            "loss: 0.119340  [ 1200/ 3009]\n",
            "loss: 0.035948  [ 1600/ 3009]\n",
            "loss: 0.080968  [ 2000/ 3009]\n",
            "loss: 0.078530  [ 2400/ 3009]\n",
            "loss: 0.166100  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.143272 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.001165  [    0/ 3009]\n",
            "loss: 0.024623  [  400/ 3009]\n",
            "loss: 0.000607  [  800/ 3009]\n",
            "loss: 0.000455  [ 1200/ 3009]\n",
            "loss: 0.005446  [ 1600/ 3009]\n",
            "loss: 0.007006  [ 2000/ 3009]\n",
            "loss: 0.007421  [ 2400/ 3009]\n",
            "loss: 0.002075  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.154272 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.018297  [    0/ 3009]\n",
            "loss: 0.003098  [  400/ 3009]\n",
            "loss: 0.392535  [  800/ 3009]\n",
            "loss: 0.152666  [ 1200/ 3009]\n",
            "loss: 0.308703  [ 1600/ 3009]\n",
            "loss: 0.343534  [ 2000/ 3009]\n",
            "loss: 0.028807  [ 2400/ 3009]\n",
            "loss: 0.055016  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.158419 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.077188  [    0/ 3009]\n",
            "loss: 0.020270  [  400/ 3009]\n",
            "loss: 0.002206  [  800/ 3009]\n",
            "loss: 0.070741  [ 1200/ 3009]\n",
            "loss: 0.017653  [ 1600/ 3009]\n",
            "loss: 0.213295  [ 2000/ 3009]\n",
            "loss: 0.486937  [ 2400/ 3009]\n",
            "loss: 0.017166  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.151423 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.023910  [    0/ 3009]\n",
            "loss: 0.222534  [  400/ 3009]\n",
            "loss: 0.000244  [  800/ 3009]\n",
            "loss: 0.054321  [ 1200/ 3009]\n",
            "loss: 0.030470  [ 1600/ 3009]\n",
            "loss: 0.025719  [ 2000/ 3009]\n",
            "loss: 0.052564  [ 2400/ 3009]\n",
            "loss: 0.016367  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 0.846202 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.014835  [    0/ 3009]\n",
            "loss: 0.210507  [  400/ 3009]\n",
            "loss: 0.037202  [  800/ 3009]\n",
            "loss: 0.048875  [ 1200/ 3009]\n",
            "loss: 0.494718  [ 1600/ 3009]\n",
            "loss: 0.209444  [ 2000/ 3009]\n",
            "loss: 0.001513  [ 2400/ 3009]\n",
            "loss: 0.009607  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.149545 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.135761  [    0/ 3009]\n",
            "loss: 0.051289  [  400/ 3009]\n",
            "loss: 0.003405  [  800/ 3009]\n",
            "loss: 0.030093  [ 1200/ 3009]\n",
            "loss: 0.257032  [ 1600/ 3009]\n",
            "loss: 0.006329  [ 2000/ 3009]\n",
            "loss: 0.018746  [ 2400/ 3009]\n",
            "loss: 0.005541  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.152704 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.143142  [    0/ 3009]\n",
            "loss: 0.046331  [  400/ 3009]\n",
            "loss: 0.057589  [  800/ 3009]\n",
            "loss: 0.016518  [ 1200/ 3009]\n",
            "loss: 0.008309  [ 1600/ 3009]\n",
            "loss: 0.004192  [ 2000/ 3009]\n",
            "loss: 0.086704  [ 2400/ 3009]\n",
            "loss: 0.001388  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.146856 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.072758  [    0/ 3009]\n",
            "loss: 0.000313  [  400/ 3009]\n",
            "loss: 0.196128  [  800/ 3009]\n",
            "loss: 0.387197  [ 1200/ 3009]\n",
            "loss: 0.030790  [ 1600/ 3009]\n",
            "loss: 0.009735  [ 2000/ 3009]\n",
            "loss: 0.017582  [ 2400/ 3009]\n",
            "loss: 0.388105  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.155905 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.009640  [    0/ 3009]\n",
            "loss: 0.019854  [  400/ 3009]\n",
            "loss: 0.045112  [  800/ 3009]\n",
            "loss: 0.009851  [ 1200/ 3009]\n",
            "loss: 0.031610  [ 1600/ 3009]\n",
            "loss: 0.015031  [ 2000/ 3009]\n",
            "loss: 0.002088  [ 2400/ 3009]\n",
            "loss: 0.003318  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.234863 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_YkvkadqAW2B",
        "outputId": "22f27d76-514f-4b56-91af-77c9a49415ee"
      },
      "source": [
        "plt.plot(np.arange(0,100),losses)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa27f911710>]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlmrIf1bEZLp"
      },
      "source": [
        "class NeuralNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork2, self).__init__()\n",
        "        self.stack = nn.Sequential(\n",
        "            nn.Conv2d(3,32,kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(36864,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24,2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.stack(x)\n",
        "        return logits"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spv-i8oGEcn5",
        "outputId": "337c8a4a-af0a-4550-fe4d-77d0daf258b2"
      },
      "source": [
        "model2 = NeuralNetwork2().to(cuda)\n",
        "print(model2)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork2(\n",
            "  (stack): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Flatten(start_dim=1, end_dim=-1)\n",
            "    (6): Linear(in_features=36864, out_features=512, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=512, out_features=24, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=24, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9RnMRQlHF6W",
        "outputId": "3ccba751-f6ce-4c0d-ed8d-a3dcbfbb5cae"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model2, loss_fn, optimizer)\n",
        "    loss = test_loop(test_loader, model2, loss_fn)\n",
        "    losses.append(loss)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.711715  [    0/ 3009]\n",
            "loss: 0.705897  [  400/ 3009]\n",
            "loss: 0.781048  [  800/ 3009]\n",
            "loss: 0.708077  [ 1200/ 3009]\n",
            "loss: 0.695257  [ 1600/ 3009]\n",
            "loss: 0.691893  [ 2000/ 3009]\n",
            "loss: 0.693443  [ 2400/ 3009]\n",
            "loss: 0.642027  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 56.2%, Avg loss: 0.673766 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.755350  [    0/ 3009]\n",
            "loss: 0.700148  [  400/ 3009]\n",
            "loss: 0.718120  [  800/ 3009]\n",
            "loss: 0.629210  [ 1200/ 3009]\n",
            "loss: 0.644932  [ 1600/ 3009]\n",
            "loss: 0.655081  [ 2000/ 3009]\n",
            "loss: 0.669446  [ 2400/ 3009]\n",
            "loss: 0.587303  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 0.640227 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.762679  [    0/ 3009]\n",
            "loss: 0.626614  [  400/ 3009]\n",
            "loss: 0.748828  [  800/ 3009]\n",
            "loss: 0.653227  [ 1200/ 3009]\n",
            "loss: 0.678577  [ 1600/ 3009]\n",
            "loss: 0.457607  [ 2000/ 3009]\n",
            "loss: 0.869075  [ 2400/ 3009]\n",
            "loss: 0.577134  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 76.1%, Avg loss: 0.556132 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.693505  [    0/ 3009]\n",
            "loss: 0.502505  [  400/ 3009]\n",
            "loss: 0.425967  [  800/ 3009]\n",
            "loss: 0.697888  [ 1200/ 3009]\n",
            "loss: 0.392529  [ 1600/ 3009]\n",
            "loss: 0.502759  [ 2000/ 3009]\n",
            "loss: 0.370721  [ 2400/ 3009]\n",
            "loss: 0.807017  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 0.514657 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.331364  [    0/ 3009]\n",
            "loss: 0.493531  [  400/ 3009]\n",
            "loss: 0.517693  [  800/ 3009]\n",
            "loss: 0.477822  [ 1200/ 3009]\n",
            "loss: 0.254994  [ 1600/ 3009]\n",
            "loss: 0.399225  [ 2000/ 3009]\n",
            "loss: 0.264680  [ 2400/ 3009]\n",
            "loss: 0.351955  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 0.509381 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.865306  [    0/ 3009]\n",
            "loss: 0.172952  [  400/ 3009]\n",
            "loss: 0.841517  [  800/ 3009]\n",
            "loss: 0.846098  [ 1200/ 3009]\n",
            "loss: 0.527412  [ 1600/ 3009]\n",
            "loss: 1.547148  [ 2000/ 3009]\n",
            "loss: 0.479856  [ 2400/ 3009]\n",
            "loss: 0.296828  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 0.472175 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.177903  [    0/ 3009]\n",
            "loss: 0.282860  [  400/ 3009]\n",
            "loss: 0.170122  [  800/ 3009]\n",
            "loss: 0.497031  [ 1200/ 3009]\n",
            "loss: 0.350640  [ 1600/ 3009]\n",
            "loss: 0.531191  [ 2000/ 3009]\n",
            "loss: 0.632520  [ 2400/ 3009]\n",
            "loss: 0.725240  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.442011 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.239665  [    0/ 3009]\n",
            "loss: 0.748299  [  400/ 3009]\n",
            "loss: 0.266596  [  800/ 3009]\n",
            "loss: 0.966097  [ 1200/ 3009]\n",
            "loss: 0.254812  [ 1600/ 3009]\n",
            "loss: 0.729323  [ 2000/ 3009]\n",
            "loss: 0.138737  [ 2400/ 3009]\n",
            "loss: 0.129802  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.429140 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.141641  [    0/ 3009]\n",
            "loss: 0.287038  [  400/ 3009]\n",
            "loss: 0.919959  [  800/ 3009]\n",
            "loss: 0.130690  [ 1200/ 3009]\n",
            "loss: 0.357816  [ 1600/ 3009]\n",
            "loss: 0.746361  [ 2000/ 3009]\n",
            "loss: 0.303294  [ 2400/ 3009]\n",
            "loss: 0.324328  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 0.425929 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.526454  [    0/ 3009]\n",
            "loss: 0.211183  [  400/ 3009]\n",
            "loss: 0.317216  [  800/ 3009]\n",
            "loss: 0.294704  [ 1200/ 3009]\n",
            "loss: 0.219923  [ 1600/ 3009]\n",
            "loss: 0.216502  [ 2000/ 3009]\n",
            "loss: 0.247918  [ 2400/ 3009]\n",
            "loss: 0.158158  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.409887 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.108303  [    0/ 3009]\n",
            "loss: 0.234122  [  400/ 3009]\n",
            "loss: 0.124939  [  800/ 3009]\n",
            "loss: 0.457307  [ 1200/ 3009]\n",
            "loss: 0.872024  [ 1600/ 3009]\n",
            "loss: 0.561566  [ 2000/ 3009]\n",
            "loss: 0.084783  [ 2400/ 3009]\n",
            "loss: 0.267610  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.406972 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.988234  [    0/ 3009]\n",
            "loss: 0.207310  [  400/ 3009]\n",
            "loss: 0.243810  [  800/ 3009]\n",
            "loss: 0.210831  [ 1200/ 3009]\n",
            "loss: 0.140878  [ 1600/ 3009]\n",
            "loss: 0.580248  [ 2000/ 3009]\n",
            "loss: 0.743210  [ 2400/ 3009]\n",
            "loss: 0.205702  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.440751 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.138902  [    0/ 3009]\n",
            "loss: 0.313473  [  400/ 3009]\n",
            "loss: 0.896971  [  800/ 3009]\n",
            "loss: 1.614543  [ 1200/ 3009]\n",
            "loss: 1.071629  [ 1600/ 3009]\n",
            "loss: 0.077596  [ 2000/ 3009]\n",
            "loss: 0.353230  [ 2400/ 3009]\n",
            "loss: 0.278893  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 0.538745 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.642798  [    0/ 3009]\n",
            "loss: 0.885413  [  400/ 3009]\n",
            "loss: 0.242328  [  800/ 3009]\n",
            "loss: 0.276141  [ 1200/ 3009]\n",
            "loss: 0.490522  [ 1600/ 3009]\n",
            "loss: 0.519415  [ 2000/ 3009]\n",
            "loss: 0.796545  [ 2400/ 3009]\n",
            "loss: 0.885233  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 0.521557 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.052964  [    0/ 3009]\n",
            "loss: 0.373672  [  400/ 3009]\n",
            "loss: 0.408586  [  800/ 3009]\n",
            "loss: 0.239320  [ 1200/ 3009]\n",
            "loss: 0.473551  [ 1600/ 3009]\n",
            "loss: 0.848234  [ 2000/ 3009]\n",
            "loss: 0.147464  [ 2400/ 3009]\n",
            "loss: 0.040510  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.363575 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.210684  [    0/ 3009]\n",
            "loss: 0.045483  [  400/ 3009]\n",
            "loss: 0.219792  [  800/ 3009]\n",
            "loss: 0.464515  [ 1200/ 3009]\n",
            "loss: 0.265839  [ 1600/ 3009]\n",
            "loss: 0.173137  [ 2000/ 3009]\n",
            "loss: 0.727704  [ 2400/ 3009]\n",
            "loss: 0.196887  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.362565 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.783489  [    0/ 3009]\n",
            "loss: 0.447749  [  400/ 3009]\n",
            "loss: 0.249983  [  800/ 3009]\n",
            "loss: 0.068901  [ 1200/ 3009]\n",
            "loss: 0.469351  [ 1600/ 3009]\n",
            "loss: 0.206290  [ 2000/ 3009]\n",
            "loss: 0.185837  [ 2400/ 3009]\n",
            "loss: 0.923424  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.8%, Avg loss: 0.353814 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.595846  [    0/ 3009]\n",
            "loss: 0.541249  [  400/ 3009]\n",
            "loss: 0.294264  [  800/ 3009]\n",
            "loss: 0.206931  [ 1200/ 3009]\n",
            "loss: 0.292013  [ 1600/ 3009]\n",
            "loss: 0.524441  [ 2000/ 3009]\n",
            "loss: 0.190251  [ 2400/ 3009]\n",
            "loss: 0.056238  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.347850 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.118232  [    0/ 3009]\n",
            "loss: 0.494000  [  400/ 3009]\n",
            "loss: 0.255106  [  800/ 3009]\n",
            "loss: 0.146838  [ 1200/ 3009]\n",
            "loss: 0.023117  [ 1600/ 3009]\n",
            "loss: 0.115445  [ 2000/ 3009]\n",
            "loss: 0.229088  [ 2400/ 3009]\n",
            "loss: 0.110753  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.350550 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.556452  [    0/ 3009]\n",
            "loss: 0.235874  [  400/ 3009]\n",
            "loss: 0.068152  [  800/ 3009]\n",
            "loss: 0.126434  [ 1200/ 3009]\n",
            "loss: 0.347096  [ 1600/ 3009]\n",
            "loss: 0.218006  [ 2000/ 3009]\n",
            "loss: 0.096414  [ 2400/ 3009]\n",
            "loss: 0.524077  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 0.631061 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.896657  [    0/ 3009]\n",
            "loss: 0.783473  [  400/ 3009]\n",
            "loss: 0.457230  [  800/ 3009]\n",
            "loss: 0.177887  [ 1200/ 3009]\n",
            "loss: 0.470935  [ 1600/ 3009]\n",
            "loss: 0.225666  [ 2000/ 3009]\n",
            "loss: 0.756398  [ 2400/ 3009]\n",
            "loss: 0.088261  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.338288 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.146667  [    0/ 3009]\n",
            "loss: 0.717931  [  400/ 3009]\n",
            "loss: 0.242449  [  800/ 3009]\n",
            "loss: 0.175843  [ 1200/ 3009]\n",
            "loss: 0.374500  [ 1600/ 3009]\n",
            "loss: 1.128326  [ 2000/ 3009]\n",
            "loss: 0.212621  [ 2400/ 3009]\n",
            "loss: 0.181792  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 71.0%, Avg loss: 0.680837 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 1.254139  [    0/ 3009]\n",
            "loss: 0.086783  [  400/ 3009]\n",
            "loss: 0.014026  [  800/ 3009]\n",
            "loss: 0.081508  [ 1200/ 3009]\n",
            "loss: 0.136452  [ 1600/ 3009]\n",
            "loss: 0.699555  [ 2000/ 3009]\n",
            "loss: 0.515623  [ 2400/ 3009]\n",
            "loss: 0.434245  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.413458 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.155622  [    0/ 3009]\n",
            "loss: 0.037453  [  400/ 3009]\n",
            "loss: 0.150519  [  800/ 3009]\n",
            "loss: 0.353349  [ 1200/ 3009]\n",
            "loss: 0.113665  [ 1600/ 3009]\n",
            "loss: 0.104747  [ 2000/ 3009]\n",
            "loss: 0.161026  [ 2400/ 3009]\n",
            "loss: 0.670281  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 79.0%, Avg loss: 0.477781 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.431234  [    0/ 3009]\n",
            "loss: 0.711103  [  400/ 3009]\n",
            "loss: 0.160983  [  800/ 3009]\n",
            "loss: 0.661031  [ 1200/ 3009]\n",
            "loss: 0.132485  [ 1600/ 3009]\n",
            "loss: 0.162321  [ 2000/ 3009]\n",
            "loss: 0.353385  [ 2400/ 3009]\n",
            "loss: 0.294625  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.366820 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.213271  [    0/ 3009]\n",
            "loss: 0.020402  [  400/ 3009]\n",
            "loss: 0.034926  [  800/ 3009]\n",
            "loss: 0.597366  [ 1200/ 3009]\n",
            "loss: 0.405835  [ 1600/ 3009]\n",
            "loss: 0.100659  [ 2000/ 3009]\n",
            "loss: 0.100782  [ 2400/ 3009]\n",
            "loss: 0.601844  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.333440 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.039107  [    0/ 3009]\n",
            "loss: 0.128670  [  400/ 3009]\n",
            "loss: 0.130664  [  800/ 3009]\n",
            "loss: 0.120917  [ 1200/ 3009]\n",
            "loss: 0.017256  [ 1600/ 3009]\n",
            "loss: 0.277486  [ 2000/ 3009]\n",
            "loss: 0.056749  [ 2400/ 3009]\n",
            "loss: 0.505215  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.327390 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.558317  [    0/ 3009]\n",
            "loss: 0.057266  [  400/ 3009]\n",
            "loss: 0.576435  [  800/ 3009]\n",
            "loss: 0.370497  [ 1200/ 3009]\n",
            "loss: 0.083310  [ 1600/ 3009]\n",
            "loss: 0.114504  [ 2000/ 3009]\n",
            "loss: 0.097639  [ 2400/ 3009]\n",
            "loss: 0.227715  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.317735 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.537438  [    0/ 3009]\n",
            "loss: 0.029624  [  400/ 3009]\n",
            "loss: 0.631468  [  800/ 3009]\n",
            "loss: 0.058956  [ 1200/ 3009]\n",
            "loss: 0.466496  [ 1600/ 3009]\n",
            "loss: 0.600036  [ 2000/ 3009]\n",
            "loss: 0.483408  [ 2400/ 3009]\n",
            "loss: 0.712210  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.317857 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.254080  [    0/ 3009]\n",
            "loss: 0.066454  [  400/ 3009]\n",
            "loss: 0.140995  [  800/ 3009]\n",
            "loss: 0.821423  [ 1200/ 3009]\n",
            "loss: 0.819443  [ 1600/ 3009]\n",
            "loss: 0.596985  [ 2000/ 3009]\n",
            "loss: 0.617405  [ 2400/ 3009]\n",
            "loss: 0.308478  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.298088 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.032066  [    0/ 3009]\n",
            "loss: 0.294722  [  400/ 3009]\n",
            "loss: 0.628836  [  800/ 3009]\n",
            "loss: 0.029795  [ 1200/ 3009]\n",
            "loss: 0.086005  [ 1600/ 3009]\n",
            "loss: 0.340056  [ 2000/ 3009]\n",
            "loss: 0.195732  [ 2400/ 3009]\n",
            "loss: 0.773366  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.308490 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.487176  [    0/ 3009]\n",
            "loss: 0.512542  [  400/ 3009]\n",
            "loss: 0.143656  [  800/ 3009]\n",
            "loss: 0.343512  [ 1200/ 3009]\n",
            "loss: 0.361330  [ 1600/ 3009]\n",
            "loss: 0.090653  [ 2000/ 3009]\n",
            "loss: 0.338889  [ 2400/ 3009]\n",
            "loss: 0.651822  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.323582 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.143074  [    0/ 3009]\n",
            "loss: 0.213931  [  400/ 3009]\n",
            "loss: 0.058581  [  800/ 3009]\n",
            "loss: 0.102967  [ 1200/ 3009]\n",
            "loss: 0.015905  [ 1600/ 3009]\n",
            "loss: 0.113902  [ 2000/ 3009]\n",
            "loss: 0.289573  [ 2400/ 3009]\n",
            "loss: 0.018185  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.322337 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.013677  [    0/ 3009]\n",
            "loss: 0.027302  [  400/ 3009]\n",
            "loss: 0.176143  [  800/ 3009]\n",
            "loss: 0.006783  [ 1200/ 3009]\n",
            "loss: 0.025181  [ 1600/ 3009]\n",
            "loss: 0.383826  [ 2000/ 3009]\n",
            "loss: 0.151664  [ 2400/ 3009]\n",
            "loss: 0.047994  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.298101 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.095547  [    0/ 3009]\n",
            "loss: 0.292424  [  400/ 3009]\n",
            "loss: 0.011002  [  800/ 3009]\n",
            "loss: 0.019398  [ 1200/ 3009]\n",
            "loss: 0.033750  [ 1600/ 3009]\n",
            "loss: 0.058871  [ 2000/ 3009]\n",
            "loss: 0.097687  [ 2400/ 3009]\n",
            "loss: 0.640427  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.291619 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.021856  [    0/ 3009]\n",
            "loss: 0.049799  [  400/ 3009]\n",
            "loss: 0.072903  [  800/ 3009]\n",
            "loss: 0.485284  [ 1200/ 3009]\n",
            "loss: 0.549467  [ 1600/ 3009]\n",
            "loss: 0.062470  [ 2000/ 3009]\n",
            "loss: 0.016815  [ 2400/ 3009]\n",
            "loss: 0.468386  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg loss: 0.558996 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.027272  [    0/ 3009]\n",
            "loss: 0.047983  [  400/ 3009]\n",
            "loss: 0.148794  [  800/ 3009]\n",
            "loss: 0.106693  [ 1200/ 3009]\n",
            "loss: 0.152875  [ 1600/ 3009]\n",
            "loss: 0.533970  [ 2000/ 3009]\n",
            "loss: 0.251033  [ 2400/ 3009]\n",
            "loss: 0.088258  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.295869 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.057280  [    0/ 3009]\n",
            "loss: 0.042504  [  400/ 3009]\n",
            "loss: 0.221389  [  800/ 3009]\n",
            "loss: 0.316236  [ 1200/ 3009]\n",
            "loss: 0.131336  [ 1600/ 3009]\n",
            "loss: 0.053026  [ 2000/ 3009]\n",
            "loss: 0.170289  [ 2400/ 3009]\n",
            "loss: 0.661655  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.276948 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.057090  [    0/ 3009]\n",
            "loss: 0.145102  [  400/ 3009]\n",
            "loss: 0.060654  [  800/ 3009]\n",
            "loss: 0.097369  [ 1200/ 3009]\n",
            "loss: 1.360102  [ 1600/ 3009]\n",
            "loss: 0.235112  [ 2000/ 3009]\n",
            "loss: 0.065366  [ 2400/ 3009]\n",
            "loss: 0.114563  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.272770 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.093003  [    0/ 3009]\n",
            "loss: 0.204854  [  400/ 3009]\n",
            "loss: 0.228901  [  800/ 3009]\n",
            "loss: 0.010832  [ 1200/ 3009]\n",
            "loss: 0.109464  [ 1600/ 3009]\n",
            "loss: 0.087519  [ 2000/ 3009]\n",
            "loss: 0.059529  [ 2400/ 3009]\n",
            "loss: 0.052867  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.347420 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.213702  [    0/ 3009]\n",
            "loss: 0.228853  [  400/ 3009]\n",
            "loss: 0.297126  [  800/ 3009]\n",
            "loss: 0.321362  [ 1200/ 3009]\n",
            "loss: 0.680654  [ 1600/ 3009]\n",
            "loss: 0.066536  [ 2000/ 3009]\n",
            "loss: 0.091023  [ 2400/ 3009]\n",
            "loss: 0.305685  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.273945 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.006649  [    0/ 3009]\n",
            "loss: 0.033944  [  400/ 3009]\n",
            "loss: 0.540856  [  800/ 3009]\n",
            "loss: 0.012566  [ 1200/ 3009]\n",
            "loss: 0.156743  [ 1600/ 3009]\n",
            "loss: 0.699563  [ 2000/ 3009]\n",
            "loss: 0.101107  [ 2400/ 3009]\n",
            "loss: 0.190124  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.309860 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.083549  [    0/ 3009]\n",
            "loss: 0.020499  [  400/ 3009]\n",
            "loss: 0.052740  [  800/ 3009]\n",
            "loss: 0.114831  [ 1200/ 3009]\n",
            "loss: 0.269933  [ 1600/ 3009]\n",
            "loss: 1.102545  [ 2000/ 3009]\n",
            "loss: 0.013960  [ 2400/ 3009]\n",
            "loss: 0.138183  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.4%, Avg loss: 0.259819 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.559715  [    0/ 3009]\n",
            "loss: 0.066336  [  400/ 3009]\n",
            "loss: 0.133803  [  800/ 3009]\n",
            "loss: 0.102599  [ 1200/ 3009]\n",
            "loss: 0.054592  [ 1600/ 3009]\n",
            "loss: 0.029684  [ 2000/ 3009]\n",
            "loss: 0.105189  [ 2400/ 3009]\n",
            "loss: 0.148556  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.307553 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.010435  [    0/ 3009]\n",
            "loss: 0.024055  [  400/ 3009]\n",
            "loss: 0.035594  [  800/ 3009]\n",
            "loss: 0.234845  [ 1200/ 3009]\n",
            "loss: 0.632556  [ 1600/ 3009]\n",
            "loss: 0.119546  [ 2000/ 3009]\n",
            "loss: 0.204551  [ 2400/ 3009]\n",
            "loss: 0.217281  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.313429 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.002566  [    0/ 3009]\n",
            "loss: 0.050801  [  400/ 3009]\n",
            "loss: 0.689970  [  800/ 3009]\n",
            "loss: 0.027387  [ 1200/ 3009]\n",
            "loss: 0.219548  [ 1600/ 3009]\n",
            "loss: 0.035808  [ 2000/ 3009]\n",
            "loss: 0.093705  [ 2400/ 3009]\n",
            "loss: 0.119880  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.284301 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.058908  [    0/ 3009]\n",
            "loss: 0.099092  [  400/ 3009]\n",
            "loss: 0.172905  [  800/ 3009]\n",
            "loss: 0.132096  [ 1200/ 3009]\n",
            "loss: 0.037793  [ 1600/ 3009]\n",
            "loss: 0.006682  [ 2000/ 3009]\n",
            "loss: 0.253893  [ 2400/ 3009]\n",
            "loss: 0.010126  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.397251 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.325469  [    0/ 3009]\n",
            "loss: 0.817043  [  400/ 3009]\n",
            "loss: 0.627767  [  800/ 3009]\n",
            "loss: 0.038809  [ 1200/ 3009]\n",
            "loss: 0.014622  [ 1600/ 3009]\n",
            "loss: 0.090391  [ 2000/ 3009]\n",
            "loss: 0.078769  [ 2400/ 3009]\n",
            "loss: 0.006134  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.285309 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.035623  [    0/ 3009]\n",
            "loss: 0.216136  [  400/ 3009]\n",
            "loss: 0.002869  [  800/ 3009]\n",
            "loss: 0.019659  [ 1200/ 3009]\n",
            "loss: 0.012295  [ 1600/ 3009]\n",
            "loss: 0.050987  [ 2000/ 3009]\n",
            "loss: 0.014024  [ 2400/ 3009]\n",
            "loss: 0.012880  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.212954 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.102933  [    0/ 3009]\n",
            "loss: 0.718785  [  400/ 3009]\n",
            "loss: 0.037147  [  800/ 3009]\n",
            "loss: 0.059148  [ 1200/ 3009]\n",
            "loss: 0.035494  [ 1600/ 3009]\n",
            "loss: 0.224930  [ 2000/ 3009]\n",
            "loss: 0.004958  [ 2400/ 3009]\n",
            "loss: 0.147441  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.222343 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.015586  [    0/ 3009]\n",
            "loss: 0.062767  [  400/ 3009]\n",
            "loss: 0.004036  [  800/ 3009]\n",
            "loss: 0.005925  [ 1200/ 3009]\n",
            "loss: 0.021460  [ 1600/ 3009]\n",
            "loss: 0.002304  [ 2000/ 3009]\n",
            "loss: 0.100230  [ 2400/ 3009]\n",
            "loss: 0.384053  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.227728 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.536548  [    0/ 3009]\n",
            "loss: 0.056401  [  400/ 3009]\n",
            "loss: 0.028797  [  800/ 3009]\n",
            "loss: 0.231863  [ 1200/ 3009]\n",
            "loss: 0.012937  [ 1600/ 3009]\n",
            "loss: 0.036724  [ 2000/ 3009]\n",
            "loss: 0.004671  [ 2400/ 3009]\n",
            "loss: 0.086848  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.235339 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.180087  [    0/ 3009]\n",
            "loss: 0.011248  [  400/ 3009]\n",
            "loss: 0.025772  [  800/ 3009]\n",
            "loss: 0.056170  [ 1200/ 3009]\n",
            "loss: 0.029920  [ 1600/ 3009]\n",
            "loss: 0.023130  [ 2000/ 3009]\n",
            "loss: 0.119869  [ 2400/ 3009]\n",
            "loss: 0.010935  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.215204 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.052787  [    0/ 3009]\n",
            "loss: 0.159526  [  400/ 3009]\n",
            "loss: 0.048870  [  800/ 3009]\n",
            "loss: 0.098035  [ 1200/ 3009]\n",
            "loss: 0.057270  [ 1600/ 3009]\n",
            "loss: 0.028382  [ 2000/ 3009]\n",
            "loss: 0.000872  [ 2400/ 3009]\n",
            "loss: 0.055467  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.211033 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.066668  [    0/ 3009]\n",
            "loss: 0.045427  [  400/ 3009]\n",
            "loss: 0.030634  [  800/ 3009]\n",
            "loss: 0.000410  [ 1200/ 3009]\n",
            "loss: 0.002358  [ 1600/ 3009]\n",
            "loss: 0.490756  [ 2000/ 3009]\n",
            "loss: 0.141261  [ 2400/ 3009]\n",
            "loss: 0.005538  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.216717 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.189964  [    0/ 3009]\n",
            "loss: 0.061585  [  400/ 3009]\n",
            "loss: 0.059436  [  800/ 3009]\n",
            "loss: 0.098524  [ 1200/ 3009]\n",
            "loss: 0.022572  [ 1600/ 3009]\n",
            "loss: 0.325416  [ 2000/ 3009]\n",
            "loss: 0.009113  [ 2400/ 3009]\n",
            "loss: 0.483147  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.221143 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.123602  [    0/ 3009]\n",
            "loss: 0.012541  [  400/ 3009]\n",
            "loss: 0.008924  [  800/ 3009]\n",
            "loss: 0.028001  [ 1200/ 3009]\n",
            "loss: 0.041111  [ 1600/ 3009]\n",
            "loss: 0.161316  [ 2000/ 3009]\n",
            "loss: 0.439316  [ 2400/ 3009]\n",
            "loss: 0.014576  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.218700 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.001368  [    0/ 3009]\n",
            "loss: 0.011280  [  400/ 3009]\n",
            "loss: 0.229602  [  800/ 3009]\n",
            "loss: 0.164365  [ 1200/ 3009]\n",
            "loss: 0.001602  [ 1600/ 3009]\n",
            "loss: 0.295999  [ 2000/ 3009]\n",
            "loss: 0.024721  [ 2400/ 3009]\n",
            "loss: 0.239548  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.208826 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.125604  [    0/ 3009]\n",
            "loss: 0.014347  [  400/ 3009]\n",
            "loss: 0.062712  [  800/ 3009]\n",
            "loss: 0.004263  [ 1200/ 3009]\n",
            "loss: 0.101383  [ 1600/ 3009]\n",
            "loss: 0.033327  [ 2000/ 3009]\n",
            "loss: 0.007881  [ 2400/ 3009]\n",
            "loss: 0.561272  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.209096 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.121307  [    0/ 3009]\n",
            "loss: 0.002635  [  400/ 3009]\n",
            "loss: 0.071714  [  800/ 3009]\n",
            "loss: 0.312861  [ 1200/ 3009]\n",
            "loss: 0.004490  [ 1600/ 3009]\n",
            "loss: 0.114921  [ 2000/ 3009]\n",
            "loss: 0.033915  [ 2400/ 3009]\n",
            "loss: 0.054698  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.188133 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.006072  [    0/ 3009]\n",
            "loss: 0.001459  [  400/ 3009]\n",
            "loss: 0.016800  [  800/ 3009]\n",
            "loss: 0.021715  [ 1200/ 3009]\n",
            "loss: 0.261786  [ 1600/ 3009]\n",
            "loss: 0.008100  [ 2000/ 3009]\n",
            "loss: 0.022308  [ 2400/ 3009]\n",
            "loss: 0.006868  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.186433 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 1.119992  [    0/ 3009]\n",
            "loss: 0.019007  [  400/ 3009]\n",
            "loss: 0.124869  [  800/ 3009]\n",
            "loss: 0.022777  [ 1200/ 3009]\n",
            "loss: 0.021165  [ 1600/ 3009]\n",
            "loss: 0.034565  [ 2000/ 3009]\n",
            "loss: 0.015211  [ 2400/ 3009]\n",
            "loss: 0.018884  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.208791 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.004318  [    0/ 3009]\n",
            "loss: 0.029748  [  400/ 3009]\n",
            "loss: 0.014781  [  800/ 3009]\n",
            "loss: 0.686249  [ 1200/ 3009]\n",
            "loss: 0.323993  [ 1600/ 3009]\n",
            "loss: 0.003493  [ 2000/ 3009]\n",
            "loss: 0.132115  [ 2400/ 3009]\n",
            "loss: 0.011684  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.179924 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.028444  [    0/ 3009]\n",
            "loss: 0.029905  [  400/ 3009]\n",
            "loss: 0.115221  [  800/ 3009]\n",
            "loss: 0.006342  [ 1200/ 3009]\n",
            "loss: 0.021636  [ 1600/ 3009]\n",
            "loss: 0.139053  [ 2000/ 3009]\n",
            "loss: 0.033270  [ 2400/ 3009]\n",
            "loss: 0.000578  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.239954 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.070939  [    0/ 3009]\n",
            "loss: 0.003253  [  400/ 3009]\n",
            "loss: 1.023592  [  800/ 3009]\n",
            "loss: 0.010428  [ 1200/ 3009]\n",
            "loss: 0.104506  [ 1600/ 3009]\n",
            "loss: 0.056250  [ 2000/ 3009]\n",
            "loss: 0.260863  [ 2400/ 3009]\n",
            "loss: 0.002603  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.200238 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.031721  [    0/ 3009]\n",
            "loss: 0.011426  [  400/ 3009]\n",
            "loss: 0.025669  [  800/ 3009]\n",
            "loss: 0.071854  [ 1200/ 3009]\n",
            "loss: 0.004346  [ 1600/ 3009]\n",
            "loss: 0.015355  [ 2000/ 3009]\n",
            "loss: 0.073710  [ 2400/ 3009]\n",
            "loss: 0.006099  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.194783 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.056827  [    0/ 3009]\n",
            "loss: 0.006316  [  400/ 3009]\n",
            "loss: 0.027297  [  800/ 3009]\n",
            "loss: 0.073569  [ 1200/ 3009]\n",
            "loss: 0.191006  [ 1600/ 3009]\n",
            "loss: 0.007177  [ 2000/ 3009]\n",
            "loss: 0.012721  [ 2400/ 3009]\n",
            "loss: 0.122002  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.194939 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.047427  [    0/ 3009]\n",
            "loss: 0.033717  [  400/ 3009]\n",
            "loss: 0.046397  [  800/ 3009]\n",
            "loss: 0.178196  [ 1200/ 3009]\n",
            "loss: 0.192990  [ 1600/ 3009]\n",
            "loss: 0.003153  [ 2000/ 3009]\n",
            "loss: 0.246383  [ 2400/ 3009]\n",
            "loss: 0.014472  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.197153 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.012189  [    0/ 3009]\n",
            "loss: 0.008321  [  400/ 3009]\n",
            "loss: 0.015485  [  800/ 3009]\n",
            "loss: 0.155864  [ 1200/ 3009]\n",
            "loss: 0.076974  [ 1600/ 3009]\n",
            "loss: 0.062411  [ 2000/ 3009]\n",
            "loss: 0.036185  [ 2400/ 3009]\n",
            "loss: 0.098237  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.219328 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.033063  [    0/ 3009]\n",
            "loss: 0.010482  [  400/ 3009]\n",
            "loss: 1.101456  [  800/ 3009]\n",
            "loss: 0.207227  [ 1200/ 3009]\n",
            "loss: 0.016984  [ 1600/ 3009]\n",
            "loss: 0.060679  [ 2000/ 3009]\n",
            "loss: 0.085786  [ 2400/ 3009]\n",
            "loss: 0.085863  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.186152 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.014237  [    0/ 3009]\n",
            "loss: 0.008362  [  400/ 3009]\n",
            "loss: 0.059688  [  800/ 3009]\n",
            "loss: 0.019283  [ 1200/ 3009]\n",
            "loss: 0.013341  [ 1600/ 3009]\n",
            "loss: 0.002386  [ 2000/ 3009]\n",
            "loss: 0.022993  [ 2400/ 3009]\n",
            "loss: 0.063859  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.190775 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.006067  [    0/ 3009]\n",
            "loss: 0.014938  [  400/ 3009]\n",
            "loss: 0.029752  [  800/ 3009]\n",
            "loss: 0.232497  [ 1200/ 3009]\n",
            "loss: 0.005524  [ 1600/ 3009]\n",
            "loss: 0.039896  [ 2000/ 3009]\n",
            "loss: 0.037427  [ 2400/ 3009]\n",
            "loss: 0.028563  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.223823 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.023205  [    0/ 3009]\n",
            "loss: 0.005795  [  400/ 3009]\n",
            "loss: 0.006179  [  800/ 3009]\n",
            "loss: 0.026254  [ 1200/ 3009]\n",
            "loss: 0.003408  [ 1600/ 3009]\n",
            "loss: 0.017294  [ 2000/ 3009]\n",
            "loss: 0.051943  [ 2400/ 3009]\n",
            "loss: 0.006927  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.217712 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.002016  [    0/ 3009]\n",
            "loss: 0.003938  [  400/ 3009]\n",
            "loss: 0.112243  [  800/ 3009]\n",
            "loss: 0.045087  [ 1200/ 3009]\n",
            "loss: 0.030736  [ 1600/ 3009]\n",
            "loss: 0.027375  [ 2000/ 3009]\n",
            "loss: 0.008110  [ 2400/ 3009]\n",
            "loss: 0.085983  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.210993 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.002764  [    0/ 3009]\n",
            "loss: 0.566190  [  400/ 3009]\n",
            "loss: 0.015490  [  800/ 3009]\n",
            "loss: 0.114851  [ 1200/ 3009]\n",
            "loss: 0.076364  [ 1600/ 3009]\n",
            "loss: 0.003924  [ 2000/ 3009]\n",
            "loss: 0.070145  [ 2400/ 3009]\n",
            "loss: 0.003886  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.198976 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.045867  [    0/ 3009]\n",
            "loss: 0.028741  [  400/ 3009]\n",
            "loss: 0.114136  [  800/ 3009]\n",
            "loss: 0.004066  [ 1200/ 3009]\n",
            "loss: 0.004808  [ 1600/ 3009]\n",
            "loss: 0.007023  [ 2000/ 3009]\n",
            "loss: 0.001620  [ 2400/ 3009]\n",
            "loss: 0.004190  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.217826 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.002527  [    0/ 3009]\n",
            "loss: 0.008536  [  400/ 3009]\n",
            "loss: 0.002528  [  800/ 3009]\n",
            "loss: 0.001528  [ 1200/ 3009]\n",
            "loss: 0.036334  [ 1600/ 3009]\n",
            "loss: 0.162887  [ 2000/ 3009]\n",
            "loss: 0.018942  [ 2400/ 3009]\n",
            "loss: 0.002940  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.195040 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.006762  [    0/ 3009]\n",
            "loss: 0.007818  [  400/ 3009]\n",
            "loss: 0.084766  [  800/ 3009]\n",
            "loss: 0.073127  [ 1200/ 3009]\n",
            "loss: 0.143585  [ 1600/ 3009]\n",
            "loss: 0.003409  [ 2000/ 3009]\n",
            "loss: 0.223054  [ 2400/ 3009]\n",
            "loss: 0.009425  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.221161 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.339593  [    0/ 3009]\n",
            "loss: 0.060837  [  400/ 3009]\n",
            "loss: 0.000541  [  800/ 3009]\n",
            "loss: 0.015170  [ 1200/ 3009]\n",
            "loss: 0.027162  [ 1600/ 3009]\n",
            "loss: 0.007985  [ 2000/ 3009]\n",
            "loss: 0.030344  [ 2400/ 3009]\n",
            "loss: 0.011487  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.185543 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.229964  [    0/ 3009]\n",
            "loss: 0.100322  [  400/ 3009]\n",
            "loss: 0.004499  [  800/ 3009]\n",
            "loss: 0.015536  [ 1200/ 3009]\n",
            "loss: 0.168483  [ 1600/ 3009]\n",
            "loss: 0.040699  [ 2000/ 3009]\n",
            "loss: 0.011484  [ 2400/ 3009]\n",
            "loss: 0.019748  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.222831 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.053352  [    0/ 3009]\n",
            "loss: 0.010847  [  400/ 3009]\n",
            "loss: 0.075460  [  800/ 3009]\n",
            "loss: 0.017181  [ 1200/ 3009]\n",
            "loss: 0.002104  [ 1600/ 3009]\n",
            "loss: 0.002123  [ 2000/ 3009]\n",
            "loss: 0.000692  [ 2400/ 3009]\n",
            "loss: 0.013210  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.204206 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.065739  [    0/ 3009]\n",
            "loss: 0.301714  [  400/ 3009]\n",
            "loss: 0.019517  [  800/ 3009]\n",
            "loss: 0.088698  [ 1200/ 3009]\n",
            "loss: 0.069003  [ 1600/ 3009]\n",
            "loss: 0.002008  [ 2000/ 3009]\n",
            "loss: 0.077431  [ 2400/ 3009]\n",
            "loss: 0.102845  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.228429 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.952123  [    0/ 3009]\n",
            "loss: 0.039410  [  400/ 3009]\n",
            "loss: 0.009688  [  800/ 3009]\n",
            "loss: 0.033955  [ 1200/ 3009]\n",
            "loss: 0.009056  [ 1600/ 3009]\n",
            "loss: 0.134471  [ 2000/ 3009]\n",
            "loss: 0.053211  [ 2400/ 3009]\n",
            "loss: 0.012799  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.229423 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.040025  [    0/ 3009]\n",
            "loss: 0.001517  [  400/ 3009]\n",
            "loss: 0.317542  [  800/ 3009]\n",
            "loss: 0.002949  [ 1200/ 3009]\n",
            "loss: 0.011448  [ 1600/ 3009]\n",
            "loss: 0.005308  [ 2000/ 3009]\n",
            "loss: 0.023394  [ 2400/ 3009]\n",
            "loss: 0.028203  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.184953 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.204139  [    0/ 3009]\n",
            "loss: 0.003344  [  400/ 3009]\n",
            "loss: 0.000827  [  800/ 3009]\n",
            "loss: 0.009044  [ 1200/ 3009]\n",
            "loss: 0.000445  [ 1600/ 3009]\n",
            "loss: 0.001391  [ 2000/ 3009]\n",
            "loss: 0.026209  [ 2400/ 3009]\n",
            "loss: 0.009114  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.177088 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.032580  [    0/ 3009]\n",
            "loss: 0.014947  [  400/ 3009]\n",
            "loss: 0.126224  [  800/ 3009]\n",
            "loss: 0.057327  [ 1200/ 3009]\n",
            "loss: 0.030780  [ 1600/ 3009]\n",
            "loss: 0.001245  [ 2000/ 3009]\n",
            "loss: 0.089182  [ 2400/ 3009]\n",
            "loss: 0.004127  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.195218 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.001389  [    0/ 3009]\n",
            "loss: 0.000323  [  400/ 3009]\n",
            "loss: 0.022877  [  800/ 3009]\n",
            "loss: 0.172521  [ 1200/ 3009]\n",
            "loss: 0.209852  [ 1600/ 3009]\n",
            "loss: 0.036781  [ 2000/ 3009]\n",
            "loss: 0.002751  [ 2400/ 3009]\n",
            "loss: 0.000419  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 89.2%, Avg loss: 0.258075 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.013297  [    0/ 3009]\n",
            "loss: 0.055379  [  400/ 3009]\n",
            "loss: 0.087756  [  800/ 3009]\n",
            "loss: 0.013887  [ 1200/ 3009]\n",
            "loss: 0.008034  [ 1600/ 3009]\n",
            "loss: 0.154472  [ 2000/ 3009]\n",
            "loss: 0.000505  [ 2400/ 3009]\n",
            "loss: 0.018036  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.192114 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.026653  [    0/ 3009]\n",
            "loss: 0.021795  [  400/ 3009]\n",
            "loss: 0.001559  [  800/ 3009]\n",
            "loss: 0.195643  [ 1200/ 3009]\n",
            "loss: 0.002604  [ 1600/ 3009]\n",
            "loss: 0.047811  [ 2000/ 3009]\n",
            "loss: 0.021945  [ 2400/ 3009]\n",
            "loss: 0.074909  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.190803 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.011322  [    0/ 3009]\n",
            "loss: 0.030642  [  400/ 3009]\n",
            "loss: 0.002860  [  800/ 3009]\n",
            "loss: 0.487855  [ 1200/ 3009]\n",
            "loss: 0.002145  [ 1600/ 3009]\n",
            "loss: 0.001327  [ 2000/ 3009]\n",
            "loss: 0.019831  [ 2400/ 3009]\n",
            "loss: 0.020152  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.191063 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.002234  [    0/ 3009]\n",
            "loss: 0.002791  [  400/ 3009]\n",
            "loss: 0.131977  [  800/ 3009]\n",
            "loss: 0.017236  [ 1200/ 3009]\n",
            "loss: 0.000345  [ 1600/ 3009]\n",
            "loss: 0.154039  [ 2000/ 3009]\n",
            "loss: 0.007235  [ 2400/ 3009]\n",
            "loss: 0.183399  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.171287 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.017451  [    0/ 3009]\n",
            "loss: 0.007637  [  400/ 3009]\n",
            "loss: 0.019134  [  800/ 3009]\n",
            "loss: 0.000013  [ 1200/ 3009]\n",
            "loss: 0.000135  [ 1600/ 3009]\n",
            "loss: 0.010495  [ 2000/ 3009]\n",
            "loss: 0.000343  [ 2400/ 3009]\n",
            "loss: 0.010131  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.236074 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.006581  [    0/ 3009]\n",
            "loss: 0.010202  [  400/ 3009]\n",
            "loss: 0.009154  [  800/ 3009]\n",
            "loss: 0.003269  [ 1200/ 3009]\n",
            "loss: 0.005554  [ 1600/ 3009]\n",
            "loss: 0.000545  [ 2000/ 3009]\n",
            "loss: 0.021496  [ 2400/ 3009]\n",
            "loss: 0.004947  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.202381 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.009128  [    0/ 3009]\n",
            "loss: 0.022003  [  400/ 3009]\n",
            "loss: 0.010909  [  800/ 3009]\n",
            "loss: 0.033784  [ 1200/ 3009]\n",
            "loss: 0.009809  [ 1600/ 3009]\n",
            "loss: 0.007817  [ 2000/ 3009]\n",
            "loss: 0.086461  [ 2400/ 3009]\n",
            "loss: 0.256660  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.196094 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.000411  [    0/ 3009]\n",
            "loss: 0.133758  [  400/ 3009]\n",
            "loss: 0.041080  [  800/ 3009]\n",
            "loss: 0.000756  [ 1200/ 3009]\n",
            "loss: 0.000638  [ 1600/ 3009]\n",
            "loss: 0.972800  [ 2000/ 3009]\n",
            "loss: 0.016895  [ 2400/ 3009]\n",
            "loss: 0.000064  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.231315 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.000266  [    0/ 3009]\n",
            "loss: 0.043275  [  400/ 3009]\n",
            "loss: 0.000550  [  800/ 3009]\n",
            "loss: 0.087086  [ 1200/ 3009]\n",
            "loss: 0.002070  [ 1600/ 3009]\n",
            "loss: 0.005622  [ 2000/ 3009]\n",
            "loss: 0.008201  [ 2400/ 3009]\n",
            "loss: 0.001006  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.185028 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.000024  [    0/ 3009]\n",
            "loss: 0.034057  [  400/ 3009]\n",
            "loss: 0.019065  [  800/ 3009]\n",
            "loss: 0.000641  [ 1200/ 3009]\n",
            "loss: 0.180563  [ 1600/ 3009]\n",
            "loss: 0.002511  [ 2000/ 3009]\n",
            "loss: 0.000235  [ 2400/ 3009]\n",
            "loss: 0.001564  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.182932 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.181693  [    0/ 3009]\n",
            "loss: 0.000027  [  400/ 3009]\n",
            "loss: 0.000437  [  800/ 3009]\n",
            "loss: 0.003232  [ 1200/ 3009]\n",
            "loss: 0.330453  [ 1600/ 3009]\n",
            "loss: 0.000859  [ 2000/ 3009]\n",
            "loss: 0.066065  [ 2400/ 3009]\n",
            "loss: 0.058993  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.203471 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.001065  [    0/ 3009]\n",
            "loss: 0.225944  [  400/ 3009]\n",
            "loss: 0.019959  [  800/ 3009]\n",
            "loss: 0.003069  [ 1200/ 3009]\n",
            "loss: 0.067013  [ 1600/ 3009]\n",
            "loss: 0.005908  [ 2000/ 3009]\n",
            "loss: 0.000709  [ 2400/ 3009]\n",
            "loss: 0.002509  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.222837 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.000622  [    0/ 3009]\n",
            "loss: 0.011569  [  400/ 3009]\n",
            "loss: 0.002145  [  800/ 3009]\n",
            "loss: 0.001567  [ 1200/ 3009]\n",
            "loss: 0.008113  [ 1600/ 3009]\n",
            "loss: 0.300387  [ 2000/ 3009]\n",
            "loss: 0.000228  [ 2400/ 3009]\n",
            "loss: 0.000766  [ 2800/ 3009]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.198401 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGsP6KugH6lF"
      },
      "source": [
        ""
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "GSdb8rxBIw-f",
        "outputId": "2b472573-4143-47fe-ee4c-b9f0b4004117"
      },
      "source": [
        "plt.plot(np.arange(0,100),losses)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa297297b50>]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y9nR6JSNktE"
      },
      "source": [
        "# accuracy is better. and in first one the model is overfitted and it will not get better accuracy \n",
        "# but in second one as time goes, it is possible that it gets better accuracy and lower loss. "
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0hO_rplN-r5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}